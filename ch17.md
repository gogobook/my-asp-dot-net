

Managed and Unmanaged Memory
WHAT’S IN THIS CHAPTER?
Allocating space on the stack and heap at runtime
Garbage collection
Releasing unmanaged resources using destructors and the
System.IDisposable interface
The syntax for using pointers in C#
Reference semantics
Using the Span type
Platform Invoke to access native APIs
WROX.COM CODE DOWNLOADS
FOR THIS CHAPTER
The Wrox.com code downloads for this chapter are found at
www.wrox.com on the Download Code tab. The source code is also
available at
https://github.com/ProfessionalCSharp/ProfessionalCSharp7 in
the directory Memory .
The code for this chapter is divided into the following major
examples:
PointerPlayground
PointerPlayground2


QuickArray
ReferenceSemantics
SpanSample
PlatformInvokeSample
MEMORY
Variables are stored on the stack. The data it references can be on the
stack (structs) or on the heap (classes). Structs also can be boxed, so
objects on the heap are created. The garbage collector needs to free up
unmanaged objects that are no longer needed from the managed heap.
Using native APIs, memory can be allocated on the native heap. The
garbage collector is not responsible for memory allocated on the native
heap. You have to free this memory on your own. There’s a lot to
consider with regard to memory.
When you use a managed environment, you can easily be misled to not
pay attention to memory management because the garbage collector
(GC) deals with that anyway. A lot of work is done by the GC; it’s very
practical to know how it works, what the small and the large object
heap are, and what data types are stored within the stack. Also, while
the garbage collector deals with managed resources, what about
unmanaged ones? You have to free them on your own. Probably your
programs are fully managed programs, but what about the types of the
Framework? For example, file types (discussed in Chapter 22, “Files
and Streams”), wrap a native file handle. This file handle needs to be
released. To release this handle early, it’s good to know the
IDisposable interface and the using statement that’s explained in this
chapter.
Other aspects are important as well. Although several language
constructs make it easier to create immutable types, mutable objects
have an advantage as well. The string class is an immutable type that’s
been available since .NET Framework 1.0. Nowadays we often have to
deal with large strings. When manipulating the string, the GC needs to
clean up a lot of objects. Directly accessing the memory of the string
and making changes makes a mutable and in different scenarios a


more performant program. The Span type that makes this possible has
been discussed in Chapter 9, “Strings and Regular Expressions,” and
in Chapter 7, “Arrays.” With arrays you’ve also seen the ArrayPool class
that also offers reducing the work of the GC.
This chapter starts with various aspects of memory management and
memory access. A good understanding of memory management and
knowledge of the pointer capabilities provided by C# will better enable
you to integrate C# code with legacy code and perform efficient
memory manipulation in performance-critical systems. This chapter
covers new ways to use the ref keyword in C# 7 for return types and
local variables. This feature reduces the need for unsafe code and
using pointers with C#. This chapter also discusses more details about
using the Span type to access a different kind of memory, such as the
managed heap, the native heap, and the stack.
MEMORY MANAGEMENT UNDER THE HOOD
One of the advantages of C# programming is that the programmer
does not need to worry about detailed memory management; the
garbage collector deals with the problem of memory cleanup on your
behalf. As a result, you get something that approximates the efficiency
of languages such as C++ without the complexity of having to handle
memory management yourself as you do in C++. However, although
you do not have to manage memory manually, it still pays to
understand what is going on behind the scenes. Understanding how
your program manages memory under the covers will help you
increase the speed and performance of your applications. This section
looks at what happens in the computer’s memory when you allocate
variables.
NOTE
The precise details of many of the topics of this section are not
presented here. This section serves as an abbreviated guide to the
general processes rather than as a statement of exact


implementation.
Value Data Types
Windows uses a system known as virtual addressing, in which the
mapping from the memory address seen by your program to the actual
location in hardware memory is entirely managed by Windows. As a
result, each process of a 32-bit application sees 4GB of available
memory, regardless of how much hardware memory you actually have
in your computer (with 64-bit applications on 64-bit processors this
number is greater). This memory contains everything that is part of
the program, including the executable code, any DLLs loaded by the
code, and the contents of all variables used when the program runs.
This 4GB of memory is known as the virtual address space or virtual
memory. For convenience, this chapter uses the shorthand memory.
NOTE
With .NET Core applications by default applications are built as
portable applications. A portable application runs on both 32-
and 64-bit environments on Windows and on Linux as long as the
.NET Core runtime is installed on the system. Not all APIs are
available on all platforms, especially if you use native APIs. For
this, you can specify specific platforms with your .NET Core
application as explained in Chapter 1, “.NET Applications and
Tools.”
Each memory location in the available 4GB is numbered starting from
zero. To access a value stored at a particular location in memory, you
need to supply the number that represents that memory location. In
any compiled high-level language, the compiler converts human-
readable variable names into memory addresses that the processor
understands.
Somewhere inside a processor’s virtual memory is an area known as
the stack. The stack stores value data types that are not members of


objects. In addition, when you call a method, the stack is used to hold
a copy of any parameters passed to the method. To understand how
the stack works, you need to understand the importance of variable
scope in C#. If variable a goes into scope before variable b , then b will
always go out of scope first. Consider the following code:
{
int a;
// do something
{
int b;
// do something else
}
}
First, the variable a is declared. Then, inside the inner code block, b is
declared. Then the inner code block terminates and b goes out of
scope, then a goes out of scope. Therefore, the lifetime of b is entirely
contained within the lifetime of a . The idea that you always de-allocate
variables in the reverse order of how you allocate them is crucial to the
way the stack works.
Note that b is in a different block from code (defined by a different
nesting of curly braces). For this reason, it is contained within a
different scope. This is termed as block scope or structure scope.
You do not know exactly where in the address space the stack is—you
don’t need to know for C# development. A stack pointer (a variable
maintained by the operating system) identifies the next free location
on the stack. When your program first starts running, the stack pointer
will point to just past the end of the block of memory that is reserved
for the stack. The stack fills downward, from high memory addresses
to low addresses. As data is put on the stack, the stack pointer is
adjusted accordingly, so it always points to just past the next free
location. This is illustrated in Figure 17-1, which shows a stack pointer
with a value of 800000 ( 0xC3500 (in hex); the next free location is the
address 799999 .


FIGURE 17-1
The following code tells the compiler that you need space in memory
to store an integer and a double, and these memory locations are
referred to as nRacingCars and engineSize . The line that declares each
variable indicates the point at which you start requiring access to this
variable. The closing curly brace of the block in which the variables are
declared identifies the point at which both variables go out of scope:
{
int nRacingCars = 10;
double engineSize = 3000.0;
// do calculations;
}
Assuming that you use the stack shown in Figure 17-1, when the
variable nRacingCars comes into scope and is assigned the value 10 , the
value 10 is placed in locations 799996 through 799999 , the 4 bytes just
below the location pointed to by the stack pointer (4 bytes because
that’s how much memory is needed to store an int ). To accommodate
this, 4 is subtracted from the value of the stack pointer, so it now
points to the location 799996 , just after the new first free location
( 799995 ).
The next line of code declares the variable engineSize (a double ) and
initializes it to the value 3000.0 . A double occupies eight bytes, so the
value 3000.0 is placed in locations 799988 through 799995 on the stack,
and the stack pointer is decremented by eight, so that it again points to
the location just after the next free location on the stack.
When engineSize goes out of scope, the runtime knows that it is no


longer needed. Because of the way variable lifetimes are always nested,
you can guarantee that whatever happened while engineSize was in
scope, the stack pointer is now pointing to the location where
engineSize is stored. To remove engineSize from the stack, the stack
pointer is incremented by eight and it now points to the location
immediately after the end of engineSize . At this point in the code, you
are at the closing curly brace, so nRacingCars also goes out of scope.
The stack pointer is incremented by 4. When another variable comes
into scope after engineSize and nRacingCars have been removed from
the stack, it overwrites the memory descending from location 799999 ,
where nRacingCars was stored.
If the compiler hits a line such as int i , j , then the order of variables
coming into scope looks indeterminate. Both variables are declared at
the same time and go out of scope at the same time. In this situation, it
does not matter in what order the two variables are removed from
memory. The compiler internally always ensures that the one that was
put in memory first is removed last, thus preserving the rule that
prohibits crossover of variable lifetimes.
Reference Data Types
Although the stack provides very high performance, it is not flexible
enough to be used for all variables. The requirement that the lifetime
of a variable must be nested is too restrictive for many purposes.
Often, you need to use a method to allocate memory for storing data
and keeping that data available long after that method has exited. This
possibility exists whenever storage space is requested with the new
operator—as is the case for all reference types. That is where the
managed heap comes in.
If you have done any C++ coding that required low-level memory
management, you are familiar with the heap. The managed heap is not
quite the same as the native heap C++ uses, however; the managed
heap works under the control of the garbage collector and provides
significant benefits compared to traditional heaps.
The managed heap (or heap for short) is just another area of memory
from the processor’s available memory. The following code


demonstrates how the heap works and how memory is allocated for
reference data types:
void DoWork()
{
Customer arabel;
arabel = new Customer();
Customer otherCustomer2 = new EnhancedCustomer();
}
This code assumes the existence of two classes, Customer and
EnhancedCustomer . The EnhancedCustomer class extends the Customer
class.
First, you declare a Customer reference called arabel . The space for this
is allocated on the stack, but remember that this is only a reference,
not an actual Customer object. The arabel reference occupies 4 bytes,
enough space to hold the address at which a Customer object will be
stored. (You need 4 bytes to represent a memory address as an integer
value between 0 and 4GB.)
The next line,
arabel = new Customer();
does several things. First, it allocates memory on the heap to store a
Customer object (a real object, not just an address). Then it sets the
value of the variable arabel to the address of the memory it has
allocated to the new Customer object. (It also calls the appropriate
Customer constructor to initialize the fields in the class instance, but
you don’t need to worry about that here.)
The Customer instance is not placed on the stack—it is placed on the
heap. In this example, you don’t know precisely how many bytes a
Customer object occupies, but assume for the sake of argument that it is
32. These 32 bytes contain the instance fields of Customer as well as
some information that .NET uses to identify and manage its class
instances.
To find a storage location on the heap for the new Customer object, the
.NET runtime looks through the heap and grabs the first adjacent,
unused block of 32 bytes. Again, for the sake of argument, assume that


this happens to be at address 200000 , and that the arabel reference
occupied locations 799996 through 799999 on the stack. This means
that before instantiating the arabel object, the memory content looks
like Figure 17-2.
FIGURE 17-2
After allocating the new Customer object, the content of memory looks
like Figure 17-3. Note that unlike the stack, memory in the heap is
allocated upward, so the free space is above the used space.


FIGURE 17-3
The next line of code both declares a Customer reference and
instantiates a Customer object. In this instance, space on the stack for
the otherCustomer2 reference is allocated and space for the mrJones
object is allocated on the heap in a single line of code:
Customer otherCustomer2 = new EnhancedCustomer();
This line allocates 4 bytes on the stack to hold the otherCustomer2
reference, stored at locations 799992 through 799995 . The
otherCustomer2 object is allocated space on the heap starting at
location 200032 .
It is clear from the example that the process of setting up a reference
variable is more complex than that for setting up a value variable, and
there is performance overhead. In fact, the process is somewhat
oversimplified here, because the .NET runtime needs to maintain
information about the state of the heap, and this information needs to
be updated whenever new data is added to the heap. Despite this
overhead, you now have a mechanism for allocating variables that is
not constrained by the limitations of the stack. By assigning the value
of one reference variable to another of the same type, you have two
variables that reference the same object in memory. When a reference
variable goes out of scope, it is removed from the stack as described in
the previous section, but the data for a referenced object is still sitting
on the heap. The data remains on the heap until either the program
terminates or the garbage collector removes it, which happens only
when it is no longer referenced by any variables.
That is the power of reference data types, and you will see this feature
used extensively in C# code. It means that you have a high degree of
control over the lifetime of your data, because it is guaranteed to exist
in the heap as long as you are maintaining some reference to it.
Garbage Collection
The previous discussion and diagrams show the managed heap
working very much like the stack, to the extent that successive objects
are placed next to each other in memory. This means that you can


determine where to place the next object by using a heap pointer that
indicates the next free memory location, which is adjusted as you add
more objects to the heap. However, things are complicated by the fact
that the lives of the heap-based objects are not coupled with the scope
of the individual stack-based variables that reference them.
When the garbage collector runs, it removes all those objects from the
heap that are no longer referenced. The GC finds all referenced objects
from a root table of references and continues to the tree of referenced
objects. Immediately after, the heap has objects scattered on it, which
are mixed up with memory that has just been freed (see Figure 17-4).
FIGURE 17-4
If the managed heap stayed like this, allocating space for new objects
would be an awkward process, with the runtime having to search
through the heap for a block of memory big enough to store each new
object. However, the garbage collector does not leave the heap in this
state. As soon as the garbage collector has freed all the objects it can, it
compacts the heap by moving all the remaining objects to form one
continuous block of memory. This means that the heap can continue
working just like the stack, as far as locating where to store new
objects. Of course, when the objects are moved about, all the
references to those objects need to be updated with the correct new
addresses, but the garbage collector handles that, too.
This action of compacting by the garbage collector is where the


managed heap works very differently from unmanaged heaps. With
the managed heap, it is just a question of reading the value of the heap
pointer, rather than iterating through a linked list of addresses to find
somewhere to put the new data.
NOTE
Generally, the garbage collector runs when the .NET runtime
determines that garbage collection is required. You can force the
garbage collector to run at a certain point in your code by calling
System.GC.Collect . System.GC is a .NET class that represents the
garbage collector, and the Collect method initiates a garbage
collection. The GC class is intended for rare situations in which you
know that it’s a good time to call the garbage collector; for
example, if you have just de-referenced a large number of objects
in your code. However, the logic of the garbage collector does not
guarantee that all unreferenced objects will be removed from the
heap in a single garbage collection pass.
NOTE
It is useful to run GC.Collect during testing. With this you can see
memory leaks where objects that should have been garbage
collected are still alive. Because the garbage collector does a good
job, it’s not a good idea to collect memory programmatically in
your production code. If you invoke Collect programmatically,
objects move faster to the next generation, as shown next. This
causes more time for the GC to run.
When objects are created, they are placed within the managed heap.
The first section of the heap is called the generation 0 section, or gen
0. As your new objects are created, they are moved into this section of
the heap. Therefore, this is where the youngest objects reside.


Your objects remain there until the first collection of objects occurs
through the garbage collection process. The objects that remain alive
after this cleansing are compacted and then moved to the next section
or generational part of the heap—the generation 1, or gen 1, section.
At this point, the generation 0 section is empty, and all new objects are
again placed in this section. Older objects that survived the GC
(garbage collection) process are further down in the generation 1
section. This movement of aged items actually occurs one more time.
The next collection process that occurs is then repeated. This means
that the items that survived the GC process from the generation 1
section are moved to the generation 2 section, and the gen 0 items go
to gen 1, again leaving gen 0 open for new objects.
NOTE
A garbage collection occurs when you allocate an item that
exceeds the capacity of the generation 0 section or when a
GC.Collect is called.
This process greatly improves the performance of your application.
Typically, your youngest objects are the ones that can be collected, and
a large number of younger-related objects might be reclaimed as well.
If these objects reside next to each other in the heap, then the garbage
collection is faster. In addition, because related objects are residing
next to each other, program execution is faster all around.
Another performance-related aspect of garbage collection in .NET is
how the framework deals with larger objects that are added to the
heap. Under the covers of .NET, larger objects have their own
managed heap, referred to as the large object heap. When objects
greater than 85,000 bytes are utilized, they go to this special heap
rather than the main heap. Your .NET application doesn’t know the
difference, as this is all managed for you. Because compressing large
items in the heap is expensive, it isn’t done for the objects residing in
the large object heap.


To improve GC even more, collections on the generation 2 section and
from the large object heap are now done on a background thread. This
means that application threads are only blocked for generation 0 and
generation 1 collections, which reduces the overall pause time,
especially for large-scale server apps. This feature is on by default for
both servers and workstations.
Another optimization to help in application performance is GC
balancing. This is specific to server GC. Typically, a server will have a
pool of threads doing roughly the same thing. The memory allocation
will be similar across all the threads. For servers there is one GC heap
per logical server. So, when one of the heaps runs out of memory and
triggers a GC, all of the other heaps most likely will benefit from the
GC as well. If a thread happens to use a lot more memory than other
threads and it causes a GC, the other threads may not be close to
requiring the GC so it’s not efficient. The GC will balance the heaps—
both the small object heap and also the large object heap. By doing this
balancing process, you can reduce unnecessary collection.
To take advantage of hardware with lots of memory, the GC has added
the GCSettings.LatencyMode property. Setting the property to one of
the values in the GCLatencyMode enumeration gives a little control to
how the GC performs collections. The following table shows the
possible values for the GCLatencyMode that can be used.
MEMBER
Batch
Interactive
LowLatency
DESCRIPTION
Disables the concurrency settings and sets the
GC for maximum throughput with the expense
of responsiveness. This overrides the
configuration setting.
The default behavior on a workstation. This
uses garbage collection concurrency and
balances throughput and responsiveness.
Conservative GC. Full collections only occur
when there is memory pressure on the system.
This setting should only be used for short
periods of time to perform specific operations.


SustainedLowLatency
NoGCRegion
Does full blocking collections only when there is
system memory pressure.
New with .NET 4.6. With GCSettings , this is a
read-only property. You can set it within a code
block calling GC.TryStartNoGCRegion and
EndNoGCRegion . Invoking TryStartNoGCRegion
you define the size of the memory that needs to
be available, which the GC tries to reach. After a
successful call to TryStartNoGCRegion you define
that the garbage collector should not run—until
calling EndNoGCRegion .
The amount of time that the LowLatency or NoGCRegion settings are
used should be kept to a minimum. The amount of memory being
allocated should be as small as possible. An out-of-memory error
could occur if you’re not careful.
STRONG AND WEAK REFERENCES
The garbage collector cannot reclaim memory of an object that still has
a reference—that is a strong reference. It can reclaim managed
memory that is not referenced from the root table directly or
indirectly. However, sometimes it can be missed to release references.
NOTE
In case you have objects that reference each other but are not
referenced from the root table—for example Object A references B,
B references C, and C references A—the GC can destroy all these
objects.
When the class or struct is instantiated in the application code, it has a
strong reference as long as there is any other code that references it.
For example, if you have a class called MyClass and you create a
reference to objects based on that class and call the variable
myClassVariable as follows, as long as myClass-Variable is in scope


there is a strong reference to the MyClass object:
var myClassVariable = new MyClass();
This means that the garbage collector cannot clean up the memory
used by the MyClass object. Generally, this is a good thing because you
might need to access the MyClass object. You might create a cache
object that has references to several other objects, like this:
var myCache = new MyCache();
myCache.Add(myClassVariable);
Now you’re finished using the myClassVariable . It can go out of scope,
or you assign null :
myClassVariable = null;
In case the garbage collector runs now, it can’t release the memory
that was referenced by the myClassVariable , because the object is still
referenced from the cache object. Such references can easily be
missed, and you can avoid this using the WeakReference .
A weak reference allows the object to be created and used, but if the
garbage collector happens to run, it collects the object and frees up the
memory. This is not something you would typically want to do because
of potential bugs and performance issues, but there are certainly
situations in which it makes sense. Weak references also don’t make
sense with small objects, as weak references have an overhead on their
own, and that might be bigger than the small object.
Weak references are created using the WeakReference class. With the
constructor, you can pass a strong reference. The sample code creates
a DataObject and passes the reference returned from the constructor.
On using WeakReference , you can check the IsAlive property. For using
the object again, the Target property of WeakReference returns a strong
reference. In case the value of the property returned is not null, you
can use the strong reference. Because the object could be collected at
any time, it’s important that the existence of the object is valid before
trying to reference it. After retrieving the strong reference successfully,
you can use it in a normal way, and now it can’t be garbage collected
because you have a strong reference again:


// Instantiate a weak reference to MathTest object
var myWeakReference = new WeakReference(new DataObject());
if (myWeakReference.IsAlive)
{
DataObject strongReference = myWeakReference.Target as
DataObject;
if (strongReference != null)
{
// use the strongReference
}
}
else
{
// reference not available
}
WORKING WITH UNMANAGED RESOURCES
The presence of the garbage collector means that you usually do not
need to worry about objects you no longer need; you simply allow all
references to those objects to go out of scope and let the garbage
collector free memory as required. However, the garbage collector
does not know how to free unmanaged resources (such as file handles,
network connections, and database connections). When managed
classes encapsulate direct or indirect references to unmanaged
resources, you need to make special provisions to ensure that the
unmanaged resources are released when an instance of the class is
garbage collected.
When defining a class, you can use two mechanisms to automate the
freeing of unmanaged resources. These mechanisms are often
implemented together because each provides a slightly different
approach:
Declare a destructor (or finalizer) as a member of your class.
Implement the System.IDisposable interface in your class.
The following sections discuss each of these mechanisms in turn and
then look at how to implement the mechanisms together for best
results.
Destructors or Finalizers


You have seen that constructors enable you to specify actions that
must take place whenever an instance of a class is created. Conversely,
destructors are called before an object is destroyed by the garbage
collector. Given this behavior, a destructor would initially seem like a
great place to put code to free unmanaged resources and perform a
general cleanup. Unfortunately, things are not so straightforward.
NOTE
Although we talk about destructors in C#, in the underlying .NET
architecture these are known as finalizers. When you define a
destructor in C#, what is emitted into the assembly by the
compiler is actually a Finalize method. It doesn’t affect any of
your source code, but you need to be aware of it when examining
generated Intermediate Language (IL) code.
The syntax for a destructor will be familiar to C++ developers. It looks
like a method, with the same name as the containing class, but
prefixed with a tilde ( ~ ). It has no return type, and takes no parameters
or access modifiers. Here is an example:
class MyClass
{
~MyClass()
{
// Finalizer implementation
}
}
When the C# compiler compiles a destructor, it implicitly translates
the destructor code to the equivalent of an override of the Finalize
method, which ensures that the Finalize method of the parent class is
executed. The following example shows the C# code equivalent to the
Intermediate Language (IL) that the compiler would generate for the
~MyClass destructor:
protected override void Finalize()
{
try


{
// Finalizer implementation
}
finally
{
base.Finalize();
}
}
As shown, the code implemented in the ~MyClass destructor is
wrapped in a try block contained in the Finalize method. A call to the
parent’s Finalize method is ensured by placing the call in a finally
block. You can read about try and finally blocks in Chapter 14,
“Errors and Exceptions.”
Experienced C++ developers make extensive use of destructors,
sometimes not only to clean up resources but also to provide
debugging information or perform other tasks. C# destructors are
used far less than their C++ equivalents. The problem with C#
destructors as compared to their C++ counterparts is that they are
nondeterministic. When a C++ object is destroyed, its destructor runs
immediately. However, because of the way the garbage collector works
when using C#, there is no way to know when an object’s destructor
will actually execute. Hence, you cannot place any code in the
destructor that relies on being run at a certain time, and you should
not rely on the destructor being called for different class instances in
any particular order. When your object is holding scarce and critical
resources that need to be freed as soon as possible, you do not want to
wait for garbage collection.
Another problem with C# destructors is that the implementation of a
destructor delays the final removal of an object from memory. Objects
that do not have a destructor are removed from memory in one pass of
the garbage collector, but objects that have destructors require two
passes to be destroyed: The first pass calls the destructor without
removing the object, and the second pass actually deletes the object. In
addition, the runtime uses a single thread to execute the Finalize
methods of all objects. If you use destructors frequently, and use them
to execute lengthy cleanup tasks, the impact on performance can be
noticeable.


The IDisposable Interface
In C#, the recommended alternative to using a destructor is using the
System.IDisposable interface. The IDisposable interface defines a
pattern (with language-level support) that provides a deterministic
mechanism for freeing unmanaged resources and avoids the garbage
collector–related problems inherent with destructors. The IDisposable
interface declares a single method named Dispose , which takes no
parameters and returns void . Here is an implementation for MyClass :
class MyClass: IDisposable
{
public void Dispose()
{
// implementation
}
}
The implementation of Dispose should explicitly free all unmanaged
resources used directly by an object and call Dispose on any
encapsulated objects that also implement the IDisposable interface. In
this way, the Dispose method provides precise control over when
unmanaged resources are freed.
Suppose that you have a class named ResourceGobbler , which relies on
the use of some external resource and implements IDisposable . If you
want to instantiate an instance of this class, use it, and then dispose of
it, you could do so like this:
var theInstance = new ResourceGobbler();
// do your processing
theInstance.Dispose();
Unfortunately, this code fails to free the resources consumed by
theInstance if an exception occurs during processing, so you should
write the code as follows using a try block (as covered in detail in
Chapter 14):
ResourceGobbler theInstance = null;
try
{
theInstance = new ResourceGobbler();
// do your processing


}
finally
{
theInstance?.Dispose();
}
The using Statement
Using try / finally ensures that Dispose is always called on
theInstance and that any resources consumed by it are always freed,
even if an exception occurs during processing. However, if you always
had to repeat such a construct, it would result in confusing code. C#
offers a syntax that you can use to guarantee that Dispose is
automatically called against an object that implements IDisposable
when its reference goes out of scope. The syntax to do this involves the
using keyword—though now in a very different context, which has
nothing to do with namespaces. The following code generates IL code
equivalent to the try block just shown:
using (var theInstance = new ResourceGobbler())
{
// do your processing
}
The using statement, followed in brackets by a reference variable
declaration and instantiation, causes that variable to be scoped to the
accompanying statement block. In addition, when that variable goes
out of scope, its Dispose method is called automatically, even if an
exception occurs.
NOTE
The using keyword has multiple uses with C#. The using
declaration is used to import namespaces. The using statement
works with objects implementing IDisposable and invokes the
Dispose method with the end of the using scope.


NOTE
With several classes both a Close and a Dispose method exists. If it
is common to close a resource (such as a file and a database), both
Close and Dispose have been implemented. Here, the Close method
simply calls Dispose . This approach provides clarity in the use of
these classes and supports the using statement. Newer classes
only implement the Dispose method as we’re already used to it.
Implementing IDisposable and a Destructor
The previous sections discussed two alternatives for freeing
unmanaged resources used by the classes you create:
The execution of a destructor is enforced by the runtime but is
nondeterministic and places an unacceptable overhead on the
runtime because of the way garbage collection works.
The IDisposable interface provides a mechanism that enables users
of a class to control when resources are freed but requires
discipline to ensure that Dispose is called.
If you are creating a finalizer, you should also implement the
IDisposable interface. You implement IDisposable on the assumption
that most programmers will call Dispose correctly, but implement a
destructor as a safety mechanism in case Dispose is not called. Here is
an example of a dual implementation:
public class ResourceHolder: IDisposable
{
private bool _isDisposed = false;
public void Dispose()
{
Dispose(true);
GC.SuppressFinalize(this);
}
protected virtual void Dispose(bool disposing)
{


if (!_isDisposed)
{
if (disposing)
{
// Cleanup managed objects by calling their
// Dispose() methods.
}
// Cleanup unmanaged objects
}
_isDisposed = true;
}
~ResourceHolder()
{
Dispose(false);
}
public void SomeMethod()
{
// Ensure object not already disposed before execution of
any method
if(_isDisposed)
{
throw new ObjectDisposedException("ResourceHolder");
}
// method implementation...
}
}
You can see from this code that there is a second protected overload of
Dispose that takes one bool parameter—and this is the method that
does all the cleaning up. Dispose(bool) is called by both the destructor
and by IDisposable.Dispose . The point of this approach is to ensure
that all cleanup code is in one place.
The parameter passed to Dispose(bool) indicates whether
Dispose(bool) has been invoked by the destructor or by
IDisposable.Dispose — Dispose(bool) should not be invoked from
anywhere else in your code. The idea is this:
If a consumer calls IDisposable.Dispose , that consumer is
indicating that all managed and unmanaged resources associated
with that object should be cleaned up.
If a destructor has been invoked, all resources still need to be


cleaned up. However, in this case, you know that the destructor
must have been called by the garbage collector and you should not
attempt to access other managed objects because you can no longer
be certain of their state. In this situation, the best you can do is
clean up the known unmanaged resources and hope that any
referenced managed objects also have destructors that will perform
their own cleaning up.
The _isDisposed member variable indicates whether the object has
already been disposed of and ensures that you do not try to dispose of
member variables more than once. It also enables you to test whether
an object has been disposed of before executing any instance methods,
as shown in SomeMethod . This simplistic approach is not thread-safe
and depends on the caller ensuring that only one thread is calling the
method concurrently. Requiring a consumer to enforce
synchronization is a reasonable assumption and one that is used
repeatedly throughout the .NET class libraries (in the Collection
classes, for example). Threading and synchronization are discussed in
Chapter 21, “Tasks and Parallel Programming.” Finally,
IDisposable.Dispose contains a call to the method
System.GC.SuppressFinalize . GC is the class that represents the garbage
collector, and the SuppressFinalize method tells the garbage collector
that a class no longer needs to have its destructor called. Because your
implementation of Dispose has already done all the cleanup required,
there’s nothing left for the destructor to do. Calling SuppressFinalize
means that the garbage collector will treat that object as if it doesn’t
have a destructor at all.
IDisposable and Finalizer Rules
Learning about finalizers and the IDisposable interface you already
learned the Dispose pattern and some rules on using these constructs.
Because releasing resources is such an important aspect with managed
code, the rules are summarized in this list:
If your class defines a member that implements IDisposable , the
class should also implement IDisposable .
Implementing IDisposable does not mean that you should also


implement a finalizer. Finalizers create additional overhead with
both creating an object and releasing the memory of the object as
an additional pass from the GC is needed. You should implement a
finalizer only if needed—for example, to release native resources.
To release native resources, a finalizer is really needed.
If a finalizer is implemented, you should also implement the
interface IDisposable . This way the native resource can be released
earlier, not only when the GC is finding out about the occupied
resource.
Within the finalization code implementation, don't access objects
that might have been finalized already. The order of finalizers is
not guaranteed.
If an object you use implements the IDisposable interface, call the
Dispose method when the object is no longer needed. In case you’re
using this object within a method, the using statement comes
handy. In case the object is a member of the class, make the class
implement IDisposable as well.
UNSAFE CODE
As you have just seen, C# is very good at hiding much of the basic
memory management from the developer, thanks to the garbage
collector and the use of references. However, sometimes you will want
direct access to memory. For example, you might want to access a
function in an external (non-.NET) DLL that requires a pointer to be
passed as a parameter (as many Windows API functions do), or
possibly for performance reasons. This section examines the C#
facilities that provide direct access to the content of memory.
Accessing Memory Directly with Pointers
Although I am introducing pointers as if they are a new topic, in
reality pointers are not new at all. You have been using references
freely in your code, and a reference is simply a type-safe pointer. You
have already seen how variables that represent objects and arrays
actually store the memory address of where the corresponding data


(the referent) is stored. A pointer is simply a variable that stores the
address of something else in the same way as a reference. The
difference is that C# does not allow you direct access to the address
contained in a reference variable. With a reference, the variable is
treated syntactically as if it stores the actual content of the referent.
C# references are designed to make the language simpler to use and to
prevent you from inadvertently doing something that corrupts the
contents of memory. With a pointer, however, the actual memory
address is available to you. This gives you a lot of power to perform
new kinds of operations. For example, you can add 4 bytes to the
address in order to examine or even modify whatever data happens to
be stored 4 bytes further in memory.
There are two main reasons for using pointers:
Backward compatibility—Despite all the facilities provided by
the .NET runtime, it is still possible to call native Windows API
functions, and for some operations this may be the only way to
accomplish your task. These API functions are generally written in
C++ or C# and often require pointers as parameters. However, in
many cases it is possible to write the DllImport declaration in a way
that avoids use of pointers—for example, by using the
System.IntPtr class.
Performance—On those occasions when speed is of the utmost
importance, pointers can provide a route to optimized
performance. If you know what you are doing, you can ensure that
data is accessed or manipulated in the most efficient way.
However, be aware that more often than not, there are other areas
of your code where you can likely make the necessary performance
improvements without resorting to using pointers. Try using a code
profiler to look for the bottlenecks in your code; Visual Studio
includes a code profiler.
Low-level memory access has a price. The syntax for using pointers is
more complex than that for reference types, and pointers are
unquestionably more difficult to use correctly. You need good
programming skills and an excellent ability to think carefully and
logically about what your code is doing to use pointers successfully.


Otherwise, it is very easy to introduce subtle, difficult-to-find bugs into
your program when using pointers. For example, it is easy to overwrite
other variables, cause stack overflows, access areas of memory that
don’t store any variables, or even overwrite information about your
code that is needed by the .NET runtime, thereby crashing your
program.
Despite these issues, pointers remain a very powerful and flexible tool
in the writing of efficient code.
WARNING
I strongly advise against using pointers unnecessarily because
your code will not only be harder to write and debug, but it will
also fail the memory type safety checks imposed by the CLR.
Writing Unsafe Code with the unsafe Keyword
As a result of the risks associated with pointers, C# allows the use of
pointers only in blocks of code that you have specifically marked for
this purpose. The keyword to do this is unsafe . You can mark an
individual method as being unsafe like this:
unsafe int GetSomeNumber()
{
// code that can use pointers
}
Any method can be marked as unsafe , regardless of what other
modifiers have been applied to it (for example, static methods or
virtual methods). In the case of methods, the unsafe modifier applies
to the method’s parameters, allowing you to use pointers as
parameters. You can also mark an entire class or struct as unsafe ,
which means that all its members are assumed unsafe:
unsafe class MyClass
{
// any method in this class can now use pointers
}


Similarly, you can mark a member as unsafe :
class MyClass
{
unsafe int* pX; // declaration of a pointer field in a
class
}
Or you can mark a block of code within a method as unsafe :
void MyMethod()
{
// code that doesn't use pointers
unsafe
{
// unsafe code that uses pointers here
}
// more 'safe' code that doesn't use pointers
}
Note, however, that you cannot mark a local variable by itself as
unsafe :
int MyMethod()
{
unsafe int *pX; // WRONG
}
If you want to use an unsafe local variable, you need to declare and use
it inside a method or block that is unsafe. There is one more step
before you can use pointers. The C# compiler rejects unsafe code
unless you tell it that your code includes unsafe blocks. You can
configure unsafe code by setting the AllowUnsafeBlocks in the csproj
project file as shown, or you can select the Allow Unsafe Code check
box in the Visual Studio Build Project Properties settings:
<PropertyGroup>
<AllowUnsafeBlocks>True</AllowUnsafeBlocks>
</PropertyGroup>
Pointer Syntax
After you have marked a block of code as unsafe , you can declare a


pointer using the following syntax:
int* pWidth, pHeight;
double* pResult;
byte*[] pFlags;
This code declares four variables: pWidth and pHeight are pointers to
integers, pResult is a pointer to a double , and pFlags is an array of
pointers to bytes. It is common practice to use the prefix p in front of
names of pointer variables to indicate that they are pointers. When
used in a variable declaration, the symbol * indicates that you are
declaring a pointer (that is, something that stores the address of a
variable of the specified type).
When you have declared variables of pointer types, you can use them
in the same way as normal variables, but first you need to learn two
more operators:
& means take the address of, and converts a value data type to a
pointer—for example, int to * int . This operator is known as the
address operator.
means get the content of this address, and converts a pointer to a
value data type—for example, * float to float . This operator is
known as the indirection operator (or the de-reference operator).
*
You can see from these definitions that & and * have opposite effects.
NOTE
You might be wondering how it is possible to use the symbols &
and * in this manner because these symbols also refer to the
operators of bitwise AND ( & ) and multiplication ( * ). Actually, it is
always possible for both you and the compiler to know what is
meant in each case because with the pointer meanings, these
symbols always appear as unary operators—they act on only one
variable and appear in front of that variable in your code. By
contrast, bitwise AND and multiplication are binary operators—
they require two operands.


The following code shows examples of how to use these operators:
int x = 10;
int* pX, pY;
pX = &x;
pY = pX;
*pY = 20;
You start by declaring an integer, x , with the value 10 followed by two
pointers to integers, pX and pY . You then set pX to point to x (that is,
you set the content of pX to the address of x ). Then you assign the value
of pX to pY , so that pY also points to x . Finally, in the statement * pY =
20 , you assign the value 20 as the contents of the location pointed to by
pY —in effect changing x to 20 because pY happens to point to x . Note
that there is no particular connection between the variables pY and x .
It is just that at the present time, pY happens to point to the memory
location at which x is held.
To get a better understanding of what is going on, consider that the
integer x is stored at memory locations 0x12F8C4 through 0x12F8C7
( 1243332 to 1243335 in decimal) on the stack (there are four locations
because an int occupies 4 bytes). Because the stack allocates memory
downward, this means that the variables pX will be stored at locations
0x12F8C0 to 0x12F8C3 , and pY will end up at locations 0x12F8BC to
0x12F8BF . Note that pX and pY also occupy 4 bytes each. That is not
because an int occupies 4 bytes, but because on a 32-bit application
you need 4 bytes to store an address. With these addresses, after
executing the previous code, the stack will look like Figure 17-5.
FIGURE 17-5


NOTE
Although this process is illustrated with integers, which are stored
consecutively on the stack on a 32-bit processor, this does not
happen for all data types. The reason is that 32-bit processors
work best when retrieving data from memory in 4-byte chunks.
Memory on such machines tends to be divided into 4-byte blocks,
and each block is sometimes known under Windows as a DWORD
because this was the name of a 32-bit unsigned int in pre-.NET
days. It is most efficient to grab DWORDs from memory—storing
data across DWORD boundaries normally results in a hardware
performance hit. For this reason, the .NET runtime normally pads
out data types so that the memory they occupy is a multiple of 4.
For example, a short occupies 2 bytes, but if a short is placed on
the stack, the stack pointer will still be decremented by 4, not 2, so
the next variable to go on the stack will still start at a DWORD
boundary.
You can declare a pointer to any value type (that is, any of the
predefined types uint , int , byte , and so on, or to a struct). However, it
is not possible to declare a pointer to a class or an array; this is
because doing so could cause problems for the garbage collector. To
work properly, the garbage collector needs to know exactly what class
instances have been created on the heap, and where they are; but if
your code started manipulating classes using pointers, you could very
easily corrupt the information on the heap concerning classes that the
.NET runtime maintains for the garbage collector. In this context, any
data type that the garbage collector can access is known as a managed
type. Pointers can only be declared as unmanaged types because the
garbage collector cannot deal with them.
Casting Pointers to Integer Types
Because a pointer really stores an integer that represents an address,
you won’t be surprised to know that the address in any pointer can be


converted to or from any integer type. Pointer-to-integer-type
conversions must be explicit. Implicit conversions are not available for
such conversions. For example, it is perfectly legitimate to write the
following:
int x = 10;
int* pX, pY;
pX = &x;
pY = pX;
*pY = 20;
ulong y = (ulong)pX;
int* pD = (int*)y;
The address held in the pointer pX is cast to a ulong and stored in the
variable y . You have then cast y back to an int * and stored it in the
new variable pD . Hence, now pD also points to the value of x .
The primary reason for casting a pointer value to an integer type is to
display it. The interpolation string (and similarly Console.Write ) does
not have any overloads that can take pointers, but they do accept and
display pointer values that have been cast to integer types:
WriteLine($"Address is {pX}"); // wrong -- will give a
compilation error
WriteLine($"Address is {(ulong)pX}"); // OK
You can cast a pointer to any of the integer types. However, because an
address occupies 4 bytes on 32-bit systems, casting a pointer to
anything other than a uint , long , or ulong is almost certain to lead to
overflow errors. (An int causes problems because its range is from
roughly –2 billion to 2 billion, whereas an address runs from zero to
about 4 billion.) If you are creating a 64-bit application, you need to
cast the pointer to ulong .
It is also important to be aware that the checked keyword does not
apply to conversions involving pointers. For such conversions,
exceptions are not raised when overflows occur, even in a checked
context. The .NET runtime assumes that if you are using pointers, you
know what you are doing and are not worried about possible
overflows.
Casting Between Pointer Types


You can also explicitly convert between pointers pointing to different
types. For example, the following is perfectly legal code:
byte aByte = 8;
byte* pByte= &aByte;
double* pDouble = (double*)pByte;
However, if you try something like this, be careful. In this example, if
you look at the double value pointed to by pDouble , you are actually
looking up some memory that contains a byte ( aByte ), combined with
some other memory, and treating it as if this area of memory
contained a double , which does not give you a meaningful value.
However, you might want to convert between types to implement the
equivalent of a C union , or you might want to cast pointers from other
types into pointers to sbyte to examine individual bytes of memory.
void Pointers
If you want to maintain a pointer but not specify to what type of data it
points, you can declare it as a pointer to a void :
int* pointerToInt;
void* pointerToVoid;
pointerToVoid = (void*)pointerToInt;
The main use of this is if you need to call an API function that requires
void * parameters. Within the C# language, there isn’t a great deal that
you can do using void pointers. In particular, the compiler flags an
error if you attempt to de-reference a void pointer using the *
operator.
Pointer Arithmetic
It is possible to add or subtract integers to and from pointers.
However, the compiler is quite clever about how it arranges this. For
example, suppose that you have a pointer to an int and you try to add
1 to its value. The compiler assumes that you actually mean you want
to look at the memory location following the int , and hence it
increases the value by 4 bytes—the size of an int . If it is a pointer to a
double , adding 1 actually increases the value of the pointer by 8 bytes,


the size of a double . Only if the pointer points to a byte or sbyte (1 byte
each) does adding 1 to the value of the pointer actually change its value
by 1.
You can use the operators +, − , +=, − =, ++, and −− with pointers, with
the variable on the right side of these operators being a long or ulong .
NOTE
It is not permitted to carry out arithmetic operations on void
pointers.
For example, assume the following definitions:
uint u = 3;
byte b = 8;
double d = 10.0;
uint* pUint= &u; // size of a uint is 4
byte* pByte = &b; // size of a byte is 1
double* pDouble = &d; // size of a double is 8
Next, assume the addresses to which these pointers point are as
follows:
pUint : 1243332
pByte : 1243328
pDouble : 1243320
Then execute this code:
++pUint; // adds (1*4) = 4 bytes to pUint
pByte -= 3; // subtracts (3*1) = 3 bytes from pByte
double* pDouble2 = pDouble + 4; // pDouble2 = pDouble + 32
bytes (4*8 bytes)
The pointers now contain this:
pUint : 1243336
pByte : 1243325


pDouble2 : 1243352
NOTE
The general rule is that adding a number X to a pointer to type T
with value P gives the result P + X*(sizeof(T)) . If successive
values of a given type are stored in successive memory locations,
pointer addition works very well, allowing you to move pointers
between memory locations. If you are dealing with types such as
byte or char , though, with sizes not in multiples of 4, successive
values will not, by default, be stored in successive memory
locations.
You can also subtract one pointer from another pointer, if both
pointers point to the same data type. In this case, the result is a long
whose value is given by the difference between the pointer values
divided by the size of the type that they represent:
double* pD1 = (double*)1243324; // note that it is perfectly
valid to
// initialize a pointer like this.
double* pD2 = (double*)1243300;
long L = pD1-pD2; // gives the result 3 (=24/sizeof(double))
The sizeof Operator
This section has been referring to the size of various data types. If you
need to use the size of a type in your code, you can use the sizeof
operator, which takes the name of a data type as a parameter and
returns the number of bytes occupied by that type, as shown in this
example:
int x = sizeof(double);
This sets x to the value 8 .
The advantage of using sizeof is that you don’t have to hard-code data
type sizes in your code, making your code more portable. For the
predefined data types, sizeof returns the following values:


sizeof(sbyte) = 1; sizeof(byte) = 1;
sizeof(short) = 2; sizeof(ushort) = 2;
sizeof(int) = 4; sizeof(uint) = 4;
sizeof(long) = 8; sizeof(ulong) = 8;
sizeof(char) = 2; sizeof(float) = 4;
sizeof(double) = 8; sizeof(bool) = 1;
You can also use sizeof for structs that you define yourself, although,
in that case, the result depends on what fields are in the struct. You
cannot use sizeof for classes.
Pointers to Structs: The Pointer Member Access
Operator
Pointers to structs work in exactly the same way as pointers to the
predefined value types. There is, however, one condition: The struct
must not contain any reference types. This is due to the restriction
mentioned earlier that pointers cannot point to any reference types. To
avoid this, the compiler flags an error if you create a pointer to any
struct that contains any reference types.
Suppose that you had a struct defined like this:
struct MyStruct
{
public long X;
public float F;
}
You could define a pointer to it as follows:
MyStruct* pStruct;
Then you could initialize it like this:
var myStruct = new MyStruct();
pStruct = &myStruct;
It is also possible to access member values of a struct through the
pointer:
(*pStruct).X = 4;
(*pStruct).F = 3.4f;


However, this syntax is a bit complex. For this reason, C# defines
another operator that enables you to access members of structs
through pointers using a simpler syntax. It is known as the pointer
member access operator, and the symbol is a dash followed by a
greater-than sign, so it looks like an arrow: -> .
NOTE
C++ developers will recognize the pointer member access
operator because C++ uses the same symbol for the same
purpose.
Using the pointer member access operator, the previous code can be
rewritten like this:
pStruct->X = 4;
pStruct->F = 3.4f;
You can also directly set up pointers of the appropriate type to point to
fields within a struct,
long* pL = &(Struct.X);
float* pF = &(Struct.F);
or,
long* pL = &(pStruct->X);
float* pF = &(pStruct->F);
Pointers to Class Members
As indicated earlier, it is not possible to create pointers to classes. That
is because the garbage collector does not maintain any information
about pointers—only about references—so creating pointers to classes
could cause garbage collection to not work properly.
However, most classes do contain value type members, and you might
want to create pointers to them. This is possible, but it requires a
special syntax. For example, suppose that you rewrite the struct from


the previous example as a class:
class MyClass
{
public long X;
public float F;
}
Then you might want to create pointers to its fields, X and F , in the
same way as you did earlier. Unfortunately, doing so produces a
compilation error:
var myObject = new MyClass();
long* pL = &(myObject.X); // wrong -- compilation error
float* pF = &(myObject.F); // wrong -- compilation error
Although X and F are unmanaged types, they are embedded in an
object, which sits on the heap. During garbage collection, the garbage
collector might move MyObject to a new location, which would leave pL
and pF pointing to the wrong memory addresses. Because of this, the
compiler does not let you assign addresses of members of managed
types to pointers in this manner.
The solution is to use the fixed keyword, which tells the garbage
collector that there may be pointers referencing members of certain
objects, so those objects must not be moved. The syntax for using
fixed looks like this when you want to declare only one pointer:
var myObject = new MyClass();
fixed (long* pObject = &(myObject.X))
{
// do something
}
You define and initialize the pointer variable in the brackets following
the keyword fixed . This pointer variable ( pObject in the example) is
scoped to the fixed block identified by the curly braces. As a result, the
garbage collector knows not to move the myObject object while the
code inside the fixed block is executing.
If you want to declare more than one pointer, you can place multiple
fixed statements before the same code block:


var myObject = new MyClass();
fixed (long* pX = &(myObject.X))
fixed (float* pF = &(myObject.F))
{
// do something
}
You can nest entire fixed blocks if you want to fix several pointers for
different periods:
var myObject = new MyClass();
fixed (long* pX = &(myObject.X))
{
// do something with pX
fixed (float* pF = &(myObject.F))
{
// do something else with pF
}
}
You can also initialize several variables within the same fixed block, if
they are of the same type:
var myObject = new MyClass();
var myObject2 = new MyClass();
fixed (long* pX = &(myObject.X), pX2 = &(myObject2.X))
{
// etc.
}
In all these cases, it is immaterial whether the various pointers you are
declaring point to fields in the same or different objects or to static
fields not associated with any class instance.
Pointer Example: PointerPlayground
For understanding pointers, it’s best to write a program using pointers
and to use the debugger. The following code snippet is from an
example named PointerPlayground . It does some simple pointer
manipulation and displays the results, enabling you to see what is
happening in memory and where variables are stored (code file
PointerPlayground/Program.cs ):
class Program


{
unsafe static void Main()
{
int x=10;
short y = -1;
byte y2 = 4;
double z = 1.5;
int* pX = &x;
short* pY = &y;
double* pZ = &z;
Console.WriteLine($"Address of x is 0x{(ulong)&x:X}, " +
$"size is {sizeof(int)}, value is {x}");
Console.WriteLine($"Address of y is 0x{(ulong)&y2:X}, " +
$"size is {sizeof(short)}, value is {y}");
Console.WriteLine($"Address of y2 is 0x{(ulong)&y2:X}, "
+
$"size is {sizeof(byte)}, value is {y2}");
Console.WriteLine($"Address of z is 0x{(ulong)&z:X}, " +
$"size is {sizeof(double)}, value is {z}");
Console.WriteLine($"Address of pX=&x is 0x{(ulong)&pX:X},
" +
$"size is {sizeof(int*)}, value is 0x{(ulong)pX:X}");
Console.WriteLine($"Address of pY=&y is 0x{(ulong)&pY:X},
" +
$"size is {sizeof(short*)}, value is 0x{(ulong)pY:X}");
Console.WriteLine($"Address of pZ=&z is 0x{(ulong)&pZ:X},
" +
$"size is {sizeof(double*)}, value is
0x{(ulong)pZ:X}");
*pX = 20;
Console.WriteLine($"After setting *pX, x = {x}");
Console.WriteLine($"*pX = {*pX}");
pZ = (double*)pX;
Console.WriteLine($"x treated as a double = {*pZ}");
Console.ReadLine();
}
}
This code declares four value variables:
An int x
A short y
A byte y2
A double z


It also declares pointers to three of these values: pX , pY , and pZ .
Next, you display the value of these variables as well as their size and
address. Note that in taking the address of pX , pY , and pZ , you are
effectively looking at a pointer to a pointer—an address of an address
of a value. Also, in accordance with the usual practice when displaying
addresses, you have used the {0:X} format specifier in the WriteLine
commands to ensure that memory addresses are displayed in
hexadecimal format.
Finally, you use the pointer pX to change the value of x to 20 and do
some pointer casting to see what happens if you try to treat the content
of x as if it were a double .
Compiling and running this code results in the following output:
Address of x is 0x376943D5A8, size is 4, value is 10
Address of y is 0x376943D5A0, size is 2, value is -1
Address of y2 is 0x376943D598, size is 1, value is 4
Address of z is 0x376943D590, size is 8, value is 1.5
Address of pX=&x is 0x376943D588, size is 8, value is
0x376943D5A8
Address of pY=&y is 0x376943D580, size is 8, value is
0x376943D5A0
Address of pZ=&z is 0x376943D578, size is 8, value is
0x376943D590
After setting *pX, x = 20
*pX = 20
x treated as a double = 9.88131291682493E-323
NOTE
When you run the application with the CoreCLR, different
addresses are shown every time you run the application.
Checking through these results confirms the description of how the
stack operates presented in the “Memory Management Under the
Hood” section earlier in this chapter. It allocates successive variables
moving downward in memory. Notice how it also confirms that blocks
of memory on the stack are always allocated in multiples of 4 bytes.


For example, y is a short (of size 2) and has the (hex) address
0xD4E710 , indicating that the memory locations reserved for it are
locations 0xD4E710 through 0xD4E713 . If the .NET runtime had been
strictly packing up variables next to each other, Y would have occupied
just two locations, 0xD4E712 and 0xD4713 .
The next example illustrates pointer arithmetic, as well as pointers to
structs and class members. This example is named
PointerPlayground2 . To start, you define a struct named
CurrencyStruct , which represents a currency value as dollars and
cents. You also define an equivalent class named CurrencyClass (code
file PointerPlayground2/Currency.cs ):
internal struct CurrencyStruct
{
public long Dollars;
public byte Cents;
public override string ToString() => $"$ {Dollars}.
{Cents}";
}
internal class CurrencyClass
{
public long Dollars = 0;
public byte Cents = 0;
public override string ToString() => $"$ {Dollars}.
{Cents}";
}
Now that you have your struct and class defined, you can apply some
pointers to them. Following is the code for the new example. Because
the code is fairly long, I’m going through it in detail. You start by
displaying the size of CurrencyStruct , creating a couple of
CurrencyStruct instances and creating some CurrencyStruct pointers.
You use the pAmount pointer to initialize the members of the amount1
CurrencyStruct and then display the addresses of your variables (code
file PointerPlayground2/Program.cs ):
unsafe static void Main()
{
Console.WriteLine($"Size of CurrencyStruct struct is " +
$"{sizeof(CurrencyStruct)}");
CurrencyStruct amount1, amount2;


CurrencyStruct* pAmount = &amount1;
long* pDollars = &(pAmount->Dollars);
byte* pCents = &(pAmount->Cents);
Console.WriteLine("Address of amount1 is
0x{(ulong)&amount1:X}");
Console.WriteLine("Address of amount2 is
0x{(ulong)&amount2:X}");
Console.WriteLine("Address of pAmount is
0x{(ulong)&pAmount:X}");
Console.WriteLine("Address of pDollars is
0x{(ulong)&pDollars:X}");
Console.WriteLine("Address of pCents is
0x{(ulong)&pCents:X}");
pAmount->Dollars = 20;
*pCents = 50;
Console.WriteLine($"amount1 contains {amount1}");
//...
}
Now you do some pointer manipulation that relies on your knowledge
of how the stack works. Due to the order in which the variables were
declared, you know that amount2 will be stored at an address
immediately below amount1 . The sizeof(CurrencyStruct) operator
returns 16 (as demonstrated in the screen output coming up), so
CurrencyStruct occupies a multiple of 4 bytes. Therefore, after you
decrement your currency pointer, it points to amount2 :
--pAmount; // this should get it to point to amount2
Console.WriteLine($"amount2 has address 0x{(ulong)pAmount:X}
" +
$"and contains {*pAmount}");
Notice that when you call Console.WriteLine , you display the contents
of amount2 , but you haven’t yet initialized it. What is displayed is
random garbage—whatever happened to be stored at that location in
memory before execution of the example. There is an important point
here: Normally, the C# compiler would prevent you from using an
uninitialized variable, but when you start using pointers, it is very easy
to circumvent many of the usual compilation checks. In this case, you
have done so because the compiler has no way of knowing that you are
actually displaying the contents of amount2 . Only you know that,
because your knowledge of the stack means that you can tell what the


effect of decrementing pAmount will be. After you start doing pointer
arithmetic, you will find that you can access all sorts of variables and
memory locations that the compiler would usually stop you from
accessing, hence the description of pointer arithmetic as unsafe.
Next, you do some pointer arithmetic on your pCents pointer. pCents
currently points to amount1.Cents , but the aim here is to get it to point
to amount2.Cents , again using pointer operations instead of directly
telling the compiler that’s what you want to do. To do this, you need to
decrement the address pCents contains by sizeof(Currency):
// do some clever casting to get pCents to point to cents
// inside amount2
CurrencyStruct* pTempCurrency = (CurrencyStruct*)pCents;
pCents = (byte*) ( --pTempCurrency );
Console.WriteLine("Address of pCents is now 0x{0:X}",
(ulong)&pCents);
Finally, you use the fixed keyword to create some pointers that point
to the fields in a class instance and use these pointers to set the value
of this instance. Notice that this is also the first time that you have
been able to look at the address of an item stored on the heap, rather
than the stack:
Console.WriteLine("\nNow with classes");
// now try it out with classes
var amount3 = new CurrencyClass();
fixed(long* pDollars2 = &(amount3.Dollars))
fixed(byte* pCents2 = &(amount3.Cents))
{
Console.WriteLine($"amount3.Dollars has address
0x{(ulong)pDollars2:X}");
Console.WriteLine($"amount3.Cents has address
0x{(ulong)pCents2:X}");
*pDollars2 = -100;
Console.WriteLine($"amount3 contains {amount3}");
}
Compiling and running this code gives output similar to this:
Size of
Address
Address
Address
CurrencyStruct struct is 16
of amount1 is 0xD290DCD7C0
of amount2 is 0xD290DCD7B0
of pAmount is 0xD290DCD7A8


Address of pDollars is 0xD290DCD7A0
Address of pCents is 0xD290DCD798
amount1 contains $ 20.50
amount2 has address 0xD290DCD7B0 and contains $ 0.0
Address of pCents is now 0xD290DCD798
Now with classes
amount3.Dollars has address 0xD292C91A70
amount3.Cents has address 0xD292C91A78
amount3 contains $ -100.0
Notice in this output the uninitialized value of amount2 that is
displayed, and notice that the size of the CurrencyStruct struct is 16 —
somewhat larger than you would expect given the size of its fields (a
long and a byte should total 9 bytes).
Using Pointers to Optimize Performance
Until now, all the examples have been designed to demonstrate the
various things that you can do with pointers. You have played around
with memory in a way that is probably interesting only to people who
like to know what’s happening under the hood, but that doesn’t really
help you write better code. Now you’re going to apply your
understanding of pointers and see an example of how judicious use of
pointers has a significant performance benefit.
Creating Stack-Based Arrays
This section explores one of the main areas in which pointers can be
useful: creating high-performance, low-overhead arrays on the stack.
As discussed in Chapter 2, “Core C#,” C# includes rich support for
handling arrays. Chapter 7, “Arrays,” give more details on arrays.
Although C# makes it very easy to use both one-dimensional and
rectangular or jagged multidimensional arrays, it suffers from the
disadvantage that these arrays are actually objects; they are instances
of System.Array . This means that the arrays are stored on the heap,
with all the overhead that this involves. There may be occasions when
you need to create a short-lived, high-performance array and don’t
want the overhead of reference objects. You can do this by using
pointers, although this is easy only for one-dimensional arrays.
To create a high-performance array, you need to use a keyword:


stackalloc . The stackalloc
command instructs the .NET runtime to
allocate an amount of memory on the stack. When you call stackalloc ,
you need to supply it with two pieces of information:
The type of data you want to store
The number of these data items you need to store
For example, to allocate enough memory to store 10 decimal data
items, you can write the following:
decimal* pDecimals = stackalloc decimal[10];
This command simply allocates the stack memory; it does not attempt
to initialize the memory to any default value. This is fine for the
purpose of this example because you are creating a high-performance
array, and initializing values unnecessarily would hurt performance.
Similarly, to store 20 double data items, you write this:
double* pDoubles = stackalloc double[20];
Although this line of code specifies the number of variables to store as
a constant, this can equally be a quantity evaluated at runtime.
Therefore, you can write the previous example like this:
int size;
size = 20; // or some other value calculated at runtime
double* pDoubles = stackalloc double[size];
You can see from these code snippets that the syntax of stackalloc is
slightly unusual. It is followed immediately by the name of the data
type you want to store (which must be a value type) and then by the
number of items you need space for, in square brackets. The number
of bytes allocated is this number multiplied by sizeof(data type ). The
use of square brackets in the preceding code sample suggests an array,
which is not too surprising. If you have allocated space for 20 doubles ,
then what you have is an array of 20 doubles . The simplest type of
array that you can have is a block of memory that stores one element
after another (see Figure 17-6).


FIGURE 17-6
This diagram also shows the pointer returned by stackalloc , which is
always a pointer to the allocated data type that points to the top of the
newly allocated memory block. To use the memory block, you simply
de-reference the returned pointer. For example, to allocate space for
20 doubles and then set the first element (element 0 of the array) to
the value 3.0 , write this:
double* pDoubles = stackalloc double[20];
*pDoubles = 3.0;
To access the next element of the array, you use pointer arithmetic. As
described earlier, if you add 1 to a pointer, its value will be increased
by the size of whatever data type it points to. In this case, that’s just
enough to take you to the next free memory location in the block that
you have allocated. Therefore, you can set the second element of the
array (element number 1 ) to the value 8.4 :
double* pDoubles = stackalloc double[20];
*pDoubles = 3.0;
*(pDoubles + 1) = 8.4;


By the same reasoning, you can access the element with index X of the
array with the expression *(pDoubles+ X) .
Effectively, you have a means by which you can access elements of
your array, but for general-purpose use, this syntax is too complex.
Fortunately, C# defines an alternative syntax using square brackets.
C# gives a very precise meaning to square brackets when they are
applied to pointers; if the variable p is any pointer type and X is an
integer, then the expression p[X] is always interpreted by the compiler
as meaning *(p + X) . This is true for all pointers, not only those
initialized using stackalloc . With this shorthand notation, you now
have a very convenient syntax for accessing your array. In fact, it
means that you have exactly the same syntax for accessing one-
dimensional, stack-based arrays as you do for accessing heap-based
arrays that are represented by the System.Array class:
double* pDoubles = stackalloc double [20];
pDoubles[0] = 3.0; // pDoubles[0] is the same as *pDoubles
pDoubles[1] = 8.4; // pDoubles[1] is the same as *
(pDoubles+1)
NOTE
This idea of applying array syntax to pointers is not new. It has
been a fundamental part of both the C and the C++ languages
ever since those languages were invented. Indeed, C++ developers
will recognize the stack-based arrays they can obtain using
stackalloc as being essentially identical to classic stack-based C
and C++ arrays. This syntax and the way it links pointers and
arrays is one reason why the C language became popular in the
1970s, and the main reason why the use of pointers became such a
popular programming technique in C and C++.
Although your high-performance array can be accessed in the same
way as a normal C# array, a word of caution is in order. The following
code in C# raises an exception:


double[] myDoubleArray = new double [20];
myDoubleArray[50] = 3.0;
The exception occurs because you are trying to access an array using
an index that is out of bounds; the index is 50 , whereas the maximum
allowed value is 19 . However, if you declare the equivalent array using
stackalloc , there is no object wrapped around the array that can
perform bounds checking. Hence, the following code does not raise an
exception:
double* pDoubles = stackalloc double [20];
pDoubles[50] = 3.0;
In this code, you allocate enough memory to hold 20 doubles . Then
you set sizeof(double) memory locations, starting at the location
given by the start of this memory + 50*sizeof(double) to hold the
double value 3.0 . Unfortunately, that memory location is way outside
the area of memory that you have allocated for the doubles. There is
no knowing what data might be stored at that address. At best, you
might have used some currently unused memory, but it is equally
possible that you might have just overwritten some locations in the
stack that were being used to store other variables or even the return
address from the method currently being executed. Again, you see that
the high performance to be gained from pointers comes at a cost; you
need to be certain you know what you are doing, or you will get some
very strange runtime bugs.
QuickArray Example
The discussion of pointers ends with a stackalloc example called
QuickArray . In this example, the program simply asks users how many
elements they want to be allocated for an array. The code then uses
stackalloc to allocate an array of long s that size. The elements of this
array are populated with the squares of the integers starting with 0 ,
and the results are displayed on the console (code file
QuickArray/Program.cs ):
class Program
{
unsafe static void Main()
{


Console.Write("How big an array do you want? \n> ");
string userInput = ReadLine();
uint size = uint.Parse(userInput);
long* pArray = stackalloc long[(int) size];
for (int i = 0; i < size; i++)
{
pArray[i] = i*i;
}
for (int i = 0; i < size; i++)
{
Console.WriteLine($"Element {i} = {*(pArray + i)}");
}
Console.ReadLine();
}
}
Here is the output from the QuickArray example:
How big
> 15
Element
Element
Element
Element
Element
Element
Element
Element
Element
Element
Element
Element
Element
Element
Element
_
an array do you want?
0 = 0
1 = 1
2 = 4
3 = 9
4 = 16
5 = 25
6 = 36
7 = 49
8 = 64
9 = 81
10 = 100
11 = 121
12 = 144
13 = 169
14 = 196
REFERENCE SEMANTICS
Chapter 3, “Objects and Types,” shows the ref keyword in action when
passing arguments to methods. When passing a struct by value, the
contents of the struct is copied. Passing a struct by reference (using the
ref keyword), the new variable references the same data.
Using C# 7.0, you also can use the ref keyword as a modifier of the


return type, and as modifier with local variables. With C# 7.2, the
readonly modifier can be added to the ref keyword to not allow
changes. C# 7.2 also adds the in keyword for passing value types by
reference without allowing them to change. These new features are
discussed in this section.
On one hand, it’s preferable to have immutable types, as these types
allow access from multiple threads without the need for
synchronization, as no thread can change a value. However,
immutable types also mean that a lot of data needs to be copied. With
value types, data need to be copied, which, of course, also costs
performance. Using reference types, different variables are needed to
reference the same data on the heap, and probably this data also needs
a copy. For example, the string type is immutable. Methods of the
string type such as ToUpper and ToLower never change the string, but
instead return a new string. Such objects need to be garbage collected
when they are no longer referenced. You’ve seen the functionality of
the garbage collector earlier in this chapter in the “Garbage Collection”
section. To avoid excessive use of the garbage collector and to copy
data without needing to use IntPtr and unsafe code, the enhanced
functionality of the ref keyword is of immense help.
The ReferenceSemantics example makes use of these namespaces:
System
System.Linq
Have a look at the following Data class. This class contains the value
type int with the variable name _anumber that is initialized in the
constructor. The method Show writes the current value of the of the
number to the console. The most interesting part is the GetNumber
method. Within the implementation, the variable _anumber is returned
using the ref keyword to return a reference to it. This is made possible
by the declaration of the return type of GetNumber ; it is declared of type
ref int to return a reference to an int . The method GetReadonlyNumber
is a method that returns a ref readonly int . ref readonly is new with
C# 7.2 to return a value type by reference, but not to allow it to change
by the caller (code file ReferenceSemantics/Data.cs ):


public class Data
{
public Data(int anumber) => _anumber = anumber;
private int _anumber;
public ref int GetNumber() => ref _anumber;
public ref readonly int GetReadonlyNumber() => ref
_anumber;
public void Show() => Console.WriteLine($"Data:
{_anumber}");
}
Let’s use the Data class and invoke the GetNumber method. The method
is declared to return ref int . However, in the following code snippet,
the result is written to an int . n is a local variable that keeps an int ,
and the result from GetNumber is copied to this variable. When you
change the value of the local variable, the data from within the Data
class is not changed (code file ReferenceSemantics/Program.cs ):
static void UseMember()
{
Console.WriteLine(nameof(UseMember));
var d = new Data(11);
int n = d.GetNumber();
n = 42;
d.Show();
Console.WriteLine();
}
When you run the application, the output shows that the Data class
still contains the initialized data after the change of the local variable:
UseMember
Data: 11
Making a small change to the implementation in the method
UseRefMember , the GetNumber method is invoked to return a ref
specifying the ref keyword before the method, and the variable n to be
a ref local, and thus it directly references _anumber within the Data
class. A local variable can also be declared with the ref readonly
modifier. The result of the method GetNumber returning a ref in t can
be assigned to a ref readonly int . This guarantees that the variable n2


cannot be changed. The compiler complains if n2 would be changed
(code file ReferenceSemantics/Program.cs ):
static void UseRefMember()
{
Console.WriteLine(nameof(UseRefMember));
var d = new Data(11);
ref int n = ref d.GetNumber();
n = 42;
d.Show();
ref readonly int n2 = d.GetNumber();
// n2 = 42; // not allowed - it's readonly!
Console.WriteLine();
}
When you run the application with this change, the data within the
Data class is changed. Fast direct access is possible without needing to
use IntPtr and unsafe code:
UseRefMember
Data: 42
Next, let’s invoke the method GetReadonlyNumber . This method returns
ref readonly int. You can assign the result to an int . Assigning a ref to
an int makes a copy. The copy can be changed, but doesn’t change the
original. Assigning the result to a ref readonly int passes the result by
reference, but the result cannot be changed (code file
ReferenceSemantics/Program.cs ):
static void UseReadonlyRefMember()
{
Console.WriteLine(nameof(UseReadonlyRefMember));
var d = new Data(11);
int n = d.GetReadonlyNumber(); // create a copy
n = 42;
d.Show();
// ref int n = d.GetReadonlyNumber(); // not allowed
ref readonly int n2 = ref d.GetReadonlyNumber();
// n2 = 42; // not allowed
Console.WriteLine();
}
The result of this method is an unchanged Data member:


UseRefMember
Data: 11
Passing ref and returning ref
Let’s get into another example: passing a ref int and returning a ref
int . The Max method receives x and y parameters by ref , and returns
the higher of these two values by ref (code file
ReferenceSemantics/Program.cs ):
static ref int Max(ref int x, ref int y)
{
if (x > y) return ref x;
else return ref y;
}
Without needing to make copies of the variables x and y , passing them
to the method Max gives a fast way to return the higher value. This can
be really useful if this method is invoked often:
static void UseMax()
{
Console.WriteLine(nameof(UseMax));
int x = 4, y = 5;
ref int z = ref Max(ref x, ref y);
Console.WriteLine($"{z} is the max of {x} and {y}");
//...
}
This is the message returned:
5 is the max of 4 and 5
Returning a reference is fast because behind the scenes you use only
pointers. However, this also means that the original item where the
reference points to can be changed. For example, changing the
variable z that references the data from x or y , depending what’s
larger, also changes the value of the original variable:
static void UseMax()
{
//...
z = x + y;
Console.WriteLine($"y after changing z: {y}");


Console.WriteLine();
}
When you run the program, you can see that y now has the value that
was assigned to z :
y after changing z: 9
Ref and Arrays
Another example to show the features of ref return and ref local shows
this keyword with arrays. The class Container defines a member of
type int[] that is initialized in the constructor. The GetItem method
returns an item of the array by reference. This allows of a fast path
directly within the array of the container (code file
ReferenceSemantics/Container.cs ):
public class Container
{
public Container(int[] data) => _data = data;
private int[] _data;
//...
public ref int GetItem(int index) => ref _data[index];
public void ShowAll()
{
Console.WriteLine(string.Join(", ", _data));
Console.WriteLine();
}
}
When using this Container , a sample array containing a list of 10 items
is passed to the constructor. The fourth item is retrieved from the
GetItem method, this item is changed to 33 , and finally all the items are
written to the console using the ShowAll method (code file
ReferenceSemantics/Program.cs ):
private static void UseItemOfContainer()
{
Console.WriteLine(nameof(UseItemOfContainer));
var c = new Container(Enumerable.Range(0, 10).Select(x =>


x).ToArray());
ref int item = ref c.GetItem(3);
item = 33;
c.ShowAll();
Console.WriteLine();
}
When you run the application, you can see the fourth item changed
from the outside:
UseItemOfContainer
0, 1, 2, 33, 4, 5, 6, 7, 8, 9
Let’s see what can be done not only with items of arrays but with
complete arrays by adding the GetData method. This method returns a
reference to the array itself (code file
ReferenceSemantics/Container.cs ):
public class Container
{
//...
public ref int[] GetData() => ref _data;
//...
}
Using the GetData method of the Container class, a reference from the
array is returned and written to the ref local variable d1 . A new array
with three elements is assigned to this variable (code file
ReferenceSemantics/Program.cs ):
private static void UseArrayOfContainer()
{
Console.WriteLine(nameof(UseArrayOfContainer));
var c = new Container(Enumerable.Range(0, 10).Select(x =>
x).ToArray());
ref int[] d1 = ref c.GetData();
d1 = new int[] { 4, 5, 6 };
c.ShowAll();
Console.WriteLine();
}
Because a reference to the array is returned, the complete array can be
replaced. The container now contains the newly created array with the


elements 4, 5, and 6:
UseArrayOfContainer
4, 5, 6
NOTE
The ref keyword for ref returns and ref locals requires references
that stay alive when returning the reference. For example, you
can return references to value types as long as they are contained
in a reference type, and thus are on the managed heap. Using
structs, you cannot define methods to return references of
members of the struct. You can return references to structs that
are received as references, as you’ve seen with the Max method.
These value types are guaranteed alive with the return of the
method, because they are passed by the caller that waits for the
return of the method.
NOTE
Chapter 3, “Objects and Types,” covers defining parameters with
the ref , out , and in modifiers. These modifiers are important in
regard to reference semantics as well. Using the in parameter
that’s new with C# 7.2 with value types defines that the value type
is passed by reference (similar to using the ref keyword with the
parameter), but doesn’t allow changing it. in is like ref readonly
for the parameters.
SPAN<T>
Chapter 3 includes creating reference types (classes) and value types
(structs). Instances of classes are stored on the managed heap. The
value of structs can be stored on the stack, or, when boxing is used, on
the managed heap. Now we have another kind: a type that can have its


value only on the stack but never on the heap, sometimes called ref-
like types. Boxing is not possible with these types. Such a type is
declared with the ref struct keyword. Using ref struct gives some
additional behaviors and restrictions. The restrictions are the
following:
They can’t be added as array items.
They can’t be used as generic type argument.
They can’t be boxed.
They can’t be static fields.
They can only be instance fields of ref-like types.
and ReadOnlySpan<T> are ref-like types covered in this section.
These types are already covered in Chapter 7 with extension methods
for arrays and in Chapter 9 with extension methods for strings. Here,
additional features are covered to reference data on the managed
heap, the stack, and the native heap.
Span<T>
Spans Referencing the Managed Heap
A Span can reference memory on the managed heap, as you’ve shown
in Chapters 7 and 9. In the following code snippet, an array is created,
and with the extension method AsSpan , a new Span is created
referencing the memory of the array on the managed heap. After
creating the Span referenced from the variable span1 , a slice of the Span
is created that is filled with the value 42 . The next Console.WriteLine
writes the values of the span span1 to the console (code file
SpanSample/Program.cs ):
private static void SpanOnTheHeap()
{
Console.WriteLine(nameof(SpanOnTheHeap));
Span<int> span1 = (new int[] { 1, 5, 11, 71, 22, 19, 21, 33
}).AsSpan();
span1.Slice(start: 4, length: 3).Fill(42);
Console.WriteLine(string.Join(", ", span1.ToArray()));
Console.WriteLine();


}
When you run the application, you can see the output of span1 with the
42 filled within the slice of the span:
SpanOnTheHeap
1, 5, 11, 71, 42, 42, 42, 33
Spans Referencing the Stack
can be used to reference memory on the stack. Referencing a
single variable on the stack is not as interesting as referencing a block
of memory; that’s why the following code snippet makes use of the
stackalloc keyword. stackalloc returns a long* which requires the
method SpanOnTheStack to be declared unsafe . A constructor of the
Span type allows passing a pointer with the additional parameter for
the size. Next, the variable span1 is used with the indexer to fill every
item (code file SpanSample/Program.cs ):
Span
private static unsafe void SpanOnTheStack()
{
Console.WriteLine(nameof(SpanOnTheStack));
long* lp = stackalloc long[20];
var span1 = new Span<long>(lp, 20);
for (int i = 0; i < 20; i++)
{
span1[i] = i;
}
Console.WriteLine(string.Join(", ", span1.ToArray()));
Console.WriteLine();
}
When you run the program, the following output shows the span with
the initialized data on the stack:
SpanOnTheStack
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,
18, 19
Spans Referencing the Native Heap


A great feature of spans is they can also reference memory on the
native heap. Memory on the native heap usually is allocated from
native APIs. In the following code snippet, the AllocHGlobal method of
the Marshal class is used to allocate 100 bytes on the native heap. The
Marshal class returns a pointer with the IntPtr type. To directly access
the int* , the ToPointer method of IntPtr is invoked. This is the pointer
required by the constructor of the Span class. Writing int values to this
memory, you need to pay attention how many bytes are needed. As an
int contains 32 bits, the number of bytes is divided by 4 with a bit shift
of two bits. After this, the native memory is filled by invoking the Fill
method of the Span . With a for loop, every item referenced from the
Span is written to the console (code file SpanSample/Program.cs ):
private static unsafe void SpanOnNativeMemory()
{
Console.WriteLine(nameof(SpanOnNativeMemory));
const int nbytes = 100;
IntPtr p = Marshal.AllocHGlobal(nbytes);
try
{
int* p2 = (int*)p.ToPointer();
Span<int> span = new Span<int>(p2, nbytes ≫ 2);
span.Fill(42);
int max = nbytes ≫ 2;
for (int i = 0; i < max; i++)
{
Console.Write($"{span[i]} ");
}
Console.WriteLine();
}
finally
{
Marshal.FreeHGlobal(p);
}
Console.WriteLine();
}
When you run the application, the values stored in the native heap are
written to the console:
SpanOnNativeMemory
42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42
42 42 42 42 42


NOTE
Using Span to access native memory and the stack, unsafe code
was needed because of the memory allocation and creation of the
Span by passing a pointer. After the initialization, unsafe code is
no longer required using the Span .
Span Extension Methods
For the Span type, extension methods are defined to make it easier to
work with this type. The following code snippet demonstrates the use
of the Overlaps , the Reverse , and the IndexOf methods. With the
Overlaps method, it is checked if the span that is used to invoke this
extension method overlaps the span passed with the argument. The
Reverse method reverses the content of the span. The IndexOf method
returns the index of the span passed with the argument (code file
SpanSample/Program.cs ):
private static void SpanExtensions()
{
Console.WriteLine(nameof(SpanExtensions));
Span<int> span1 = (new int[] { 1, 5, 11, 71, 22, 19, 21, 33
}).AsSpan();
Span<int> span2 = span1.Slice(3, 4);
bool overlaps = span1.Overlaps(span2);
Console.WriteLine($"span1 overlaps span2: {overlaps}");
span1.Reverse();
Console.WriteLine($"span1 reversed: {string.Join(", ",
span1.ToArray())}");
Console.WriteLine($"span2 (a slice) after reversing span1:
" +
$"{string.Join(", ", span2.ToArray())}");
int index = span1.IndexOf(span2);
Console.WriteLine($"index of span2 in span1: {index}");
Console.WriteLine();
}
Running the program produces this output:
SpanExtensions


span1
span1
span2
index
overlaps span2: True
reversed: 33, 21, 19, 22, 71, 11, 5, 1
(a slice) after reversing span1: 22, 71, 11, 5
of span2 in span1: 3
Other extension methods defined for the Span type are StartWith to
check if a span starts with the sequence of another span, SequenceEqual
to compare the sequence of two spans, SequenceCompareTo for ordering
of sequences, and LastIndexOf which returns the first matching index
starting from the end of the span.
PLATFORM INVOKE
Not all the features of Windows API calls are available from .NET. This
is true not only for old Windows API calls but also for very new
features. Maybe you’ve written some DLLs that export unmanaged
methods and you would like to use them from C# as well.
To reuse an unmanaged library that doesn’t contain COM objects—it
contains only exported functions—you can use Platform Invoke
(P/Invoke). With P/Invoke, the CLR loads the DLL that includes the
function that should be called and marshals the parameters.
To use the unmanaged function, first you have to determine the name
of the function as it is exported. You can do this by using the dumpbin
tool with the /exports option.
For example, the command
dumpbin /exports c:\windows\system32\kernel32.dll | more
lists all exported functions from the DLL kernel32.dll . In the
example, you use the CreateHardLink Windows API function to create a
hard link to an existing file. With this API call, you can have several
filenames that reference the same file as long as the filenames are on
one hard disk only. This API call is not available from .NET Core, so
you must use platform invoke.
To call a native function, you have to define a C# external method with
the same number of arguments, and the argument types that are
defined with the unmanaged method must have mapped types with


managed code.
The Windows API call CreateHardLink has this definition in C++:
BOOL CreateHardLink(
LPCTSTR lpFileName,
LPCTSTR lpExistingFileName,
LPSECURITY_ATTRIBUTES lpSecurityAttributes);
This definition must be mapped to .NET data types. The return type is
a BOOL with unmanaged code; this simply maps to the bool data type.
LPCTSTR defines a long pointer to a const string. The Windows API uses
the Hungarian naming convention for the data type. LP is a long
pointer, C is a const, and STR is a null-terminated string. The T marks
the type as a generic type, and the type is resolved to either LPCSTR (an
ANSI string) or LPWSTR (a wide Unicode string), depending on the
compiler’s settings to 32 or 64 bit. C strings map to the .NET type
String. LPSECURITY_ATTRIBUTES , which is a long pointer to a struct of
type SECURITY_ATTRIBUTES . Because you can pass NULL to this argument,
mapping this type to IntPtr is okay. The C# declaration of this method
must be marked with the extern modifier because there’s no
implementation of this method within the C# code. Instead, the
method implementation is in the DLL kernel32.dll , which is
referenced with the attribute [DllImport] . The return type of the .NET
declaration CreateHardLink is of type bool , and the native method
CreateHardLink returns a BOOL , so some additional clarification is
useful. Because there are different Boolean data types with C++ (for
example, the native bool and the Windows-defined BOOL , which have
different values), the attribute [MarshalAs] specifies to what native
type the .NET type bool should map:
[DllImport("kernel32.dll", SetLastError="true",
EntryPoint="CreateHardLink", CharSet=CharSet.Unicode)]
[return: MarshalAs(UnmanagedType.Bool)]
public static extern bool CreateHardLink(string newFileName,
string existingFilename, IntPtr securityAttributes);
NOTE


The website http://www.pinvoke.net is very helpful with the
conversion from native to managed code.
The settings that you can specify with the attribute [DllImport] are
listed in the following table.
DLLIMPORT
DESCRIPTION
PROPERTY OR
FIELD
EntryPoint
You can give the C# declaration of the function a
different name than the one it has with the
unmanaged library. The name of the method in
the unmanaged library is defined in the field
EntryPoint .
CallingConvention Depending on the compiler or compiler settings
that were used to compile the unmanaged
function, you can use different calling
conventions. The calling convention defines how
the parameters are handled and where to put
them on the stack. You can define the calling
convention by setting an enumerable value. The
Windows API usually uses the StdCall calling
convention on the Windows operating system,
and it uses the Cdecl calling convention on
Windows CE. Setting the value to
CallingConvention.Winapi works for the Windows
API in both the Windows and the Windows CE
environments.
CharSet
String parameters can be either ANSI or Unicode.
With the CharSet setting, you can define how
strings are managed. Possible values that are
defined with the CharSet enumeration are Ansi ,
Unicode , and Auto . CharSet.Auto uses Unicode on
the Windows NT platform, and ANSI on
Microsoft’s older operating systems.
SetLastError
If the unmanaged function sets an error by using


the Windows API SetLastError , you can set the
SetLastError field to true . This way, you can read
the error number afterward by using
Marshal.GetLastWin32Error .
To make the CreateHardLink method easier to use from a .NET
environment, you should follow these guidelines:
Create an internal class named NativeMethods that wraps the
platform invoke method calls.
Create a public class to offer the native method functionality to
.NET applications.
Use security attributes to mark the required security.
In the following example, the public method CreateHardLink in the
class FileUtility is the method that can be used by .NET applications.
This method has the filename arguments reversed compared to the
native Windows API method CreateHardLink . The first argument is the
name of the existing file, and the second argument is the new file. This
is similar to other classes in the framework, such as File.Copy .
Because the third argument used to pass the security attributes for the
new filename is not used with this implementation, the public method
has just two parameters. The return type is changed as well. Instead of
returning an error by returning the value false , an exception is
thrown. In case of an error, the unmanaged method CreateHardLink
sets the error number with the unmanaged API SetLastError . To read
this value from .NET, the [DllImport] field SetLastError is set to true .
Within the managed method CreateHardLink , the error number is read
by calling Marshal.GetLastWin32Error . To create an error message
from this number, the Win32Exception class from the namespace
System.ComponentModel is used. This class accepts an error number
with the constructor, and returns a localized error message. In case of
an error, an exception of type IOException is thrown, which has an
inner exception of type Win32Exception . The public method
CreateHardLink has the FileIOPermission attribute applied to check
whether the caller has the necessary permission (code file
PInvokeSampleLib/NativeMethods.cs ).


[SecurityCritical]
internal static class NativeMethods
{
[DllImport("kernel32.dll", SetLastError = true,
EntryPoint = "CreateHardLinkW", CharSet =
CharSet.Unicode)]
[return: MarshalAs(UnmanagedType.Bool)]
private static extern bool CreateHardLink(
[In, MarshalAs(UnmanagedType.LPWStr)] string newFileName,
[In, MarshalAs(UnmanagedType.LPWStr)] string
existingFileName,
IntPtr securityAttributes);
internal static void CreateHardLink(string oldFileName,
string newFileName)
{
if (!CreateHardLink(newFileName, oldFileName,
IntPtr.Zero))
{
var ex = new
Win32Exception(Marshal.GetLastWin32Error());
throw new IOException(ex.Message, ex);
}
}
}
public static class FileUtility
{
[FileIOPermission(SecurityAction.LinkDemand, Unrestricted =
true)]
public static void CreateHardLink(string oldFileName,
string newFileName)
{
NativeMethods.CreateHardLink(oldFileName, newFileName);
}
}
This library uses the following dependency and namespaces:
Dependency:
System.Security.Permissions
Namespaces:
System
System.IO


System.Runtime.InteropServices
System.Security
System.Security.Permissions
WARNING
The PlatformInvoke sample compiles successfully on Linux but
doesn’t run because the library kernel32.dll cannot be found on
the Linux operating system.
You can now use this class to easily create hard links. If the file passed
with the first argument of the program does not exist, you get an
exception with the message: The system cannot find the file
specified . If the file exists, you get a new filename referencing the
original file. You can easily verify this by changing text in one file; it
shows up in the other file as well (code file PInvokeSample/Program.cs ):
class Program
{
static void Main(string[] args)
{
if (args.Length != 2)
{
Console.WriteLine("usage: PInvokeSample " +
"existingfilename newfilename");
return;
}
try
{
FileUtility.CreateHardLink(args[0], args[1]);
}
catch (IOException ex)
{
Console.WriteLine(ex.Message);
}
}
}


With native method calls on Windows, often you have to use Windows
handles. A Window handle is a 32- or 64-bit value for which,
depending on the handle types, some values are not allowed. With
.NET 1.0 for handles, usually the IntPtr structure was used because
you can set every possible 32-bit value with this structure. However,
with some handle types, this led to security problems and possible
threading race conditions and leaked handles with the finalization
phase. That’s why .NET 2.0 introduced the SafeHandle class. The class
SafeHandle is an abstract base class for every Windows handle.
Derived classes inside the Microsoft.Win32.SafeHandles namespace
are SafeHandleZeroOrMinusOneIsInvalid and
SafeHandleMinusOneIsInvalid . As the name indicates, these classes do
not accept invalid 0 or –1 values. Further derived handle types are
SafeFileHandle , SafeWaitHandle , SafeNCryptHandle , and
SafePipeHandle , which can be used by the specific Windows API calls.
For example, to map the Windows API CreateFile , you can use the
following declaration to return a SafeFileHandle . Of course, usually
you could use the .NET classes File and FileInfo instead.
[DllImport("Kernel32.dll", SetLastError = true,
CharSet = CharSet.Unicode)]
internal static extern SafeFileHandle CreateFile(
string fileName,
[MarshalAs(UnmanagedType.U4)] FileAccess fileAccess,
[MarshalAs(UnmanagedType.U4)] FileShare fileShare,
IntPtr securityAttributes,
[MarshalAs(UnmanagedType.U4)] FileMode creationDisposition,
int flags,
SafeFileHandle template);
SUMMARY
Remember that in order to become a truly proficient C# programmer,
you must have a solid understanding of how memory allocation and
garbage collection work. This chapter described how the CLR manages
and allocates memory on the heap and the stack. It also illustrated
how to write classes that free unmanaged resources correctly, and how
to use pointers in C#. These are both advanced topics that are poorly
understood and often implemented incorrectly by novice


programmers. At a minimum, this chapter should have helped you
understand how to release resources using the IDisposable interface
and the using statement.
You’ve also seen C# 7.0 and 7.2 enhancements passing values by
reference and returning values by reference, particularly ref return and
ref locals, as well as using the ref readonly modifier.
The next chapter covers a roundtrip through all features of Visual
Studio 2017.